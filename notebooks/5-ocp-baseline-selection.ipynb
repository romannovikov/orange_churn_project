{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 28994,
     "status": "ok",
     "timestamp": 1602704356618,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "ZQ8Crc6Btd0s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# пропроцессинг\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from feature_engine.categorical_encoders import RareLabelCategoricalEncoder\n",
    "\n",
    "\n",
    "# моделирование\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 29292,
     "status": "ok",
     "timestamp": 1602704357988,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "jfpN7puV-bu0"
   },
   "outputs": [],
   "source": [
    "# добавляем в sys.path директорию со скриптами\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'ocp')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 35261,
     "status": "ok",
     "timestamp": 1602704365925,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "P5kvTm5Tt1s9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# загружаем необходимые скрипты\n",
    "from data.loading import load_data\n",
    "from data.saving import save_obj\n",
    "from data.splitting import train_holdout_split, predefined_cv_strategy\n",
    "from features.stats import tconfint_mean\n",
    "from models.preprocessing import PandasSimpleImputer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# задаем константы\n",
    "SEED = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 35292,
     "status": "ok",
     "timestamp": 1602704369512,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "svCYq4lfQcDz"
   },
   "outputs": [],
   "source": [
    "train, test, numerical, categorical = load_data('../data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 34774,
     "status": "ok",
     "timestamp": 1602704369515,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "_7zePdKgeNVZ"
   },
   "outputs": [],
   "source": [
    "numerical, categorical = numerical.tolist(), categorical.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NfKNH217Ybp"
   },
   "source": [
    "# Выбор бэйзлайн-модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_LEMzc7d-8Y"
   },
   "source": [
    "В EDA мы выяснили, что часть объектов (~10%) имеет пропущенные значения в большей части признакового пространства как в трейне, так и в тесте. Для того, чтобы корректно проводить кросс-валидацию на наших данных необходимо, чтобы распределения признаков на объектах было одинаково в обучающих и тестовом фолдах, поэтому стратификацию данных нужно делать не только по целевой переменной, но и по принадлежности к частям с разным распределением пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 23702,
     "status": "ok",
     "timestamp": 1602704372961,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "t_5xA9CiAtq8"
   },
   "outputs": [],
   "source": [
    "# сразу заполним категориальные признаки значением 'unknown'\n",
    "# как трэйне, так и в тесте\n",
    "# потому как RareLabelCategoricalEncoder не обрабатывает признаки с пропусками\n",
    "train[categorical] = train[categorical].fillna('unknown')\n",
    "test[categorical] = test[categorical].fillna('unknown')\n",
    "\n",
    "# сохраним обработанные данные\n",
    "train.to_csv('../data/processed/train.csv')\n",
    "test.to_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 21977,
     "status": "ok",
     "timestamp": 1602704372963,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "m_Ekd8VeCPhv"
   },
   "outputs": [],
   "source": [
    "(X, X_train, X_holdout, \n",
    " y, y_train, y_holdout, \n",
    " stratify) = train_holdout_split(train, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 1580,
     "status": "ok",
     "timestamp": 1602704551365,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "3g0h0XfKDMKg",
    "outputId": "f2eaaa79-5dcc-4c96-fd6f-5a75bb1a5d7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    2     3     4 ... 26797 26798 26799] TEST: [    0     1    14 ... 26769 26782 26784]\n",
      "TRAIN: [    0     1     4 ... 26796 26797 26799] TEST: [    2     3     8 ... 26792 26793 26798]\n",
      "TRAIN: [    0     1     2 ... 26793 26797 26798] TEST: [    6     7    10 ... 26795 26796 26799]\n",
      "TRAIN: [    0     1     2 ... 26797 26798 26799] TEST: [    9    11    15 ... 26772 26775 26787]\n",
      "TRAIN: [    0     1     2 ... 26796 26798 26799] TEST: [    4     5    13 ... 26790 26791 26797]\n"
     ]
    }
   ],
   "source": [
    "# задаем стратегию кросс-валидации\n",
    "cv = predefined_cv_strategy(X_train, stratify, random_state=SEED)\n",
    "\n",
    "for train_index, test_index in cv.split():\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a0WVd3gi7cHi"
   },
   "outputs": [],
   "source": [
    "# сформируем базовый пайплайн предобработки\n",
    "\n",
    "\n",
    "# для категориальных переменных -\n",
    "\n",
    "# tol - порок укрупнения редких категорий в признаках, \n",
    "# являясь относительной частотой, зависит от числа строк в данных,\n",
    "# вычислим его значение, приняв за редкие категории, те на которые\n",
    "# приходится меньше 20 строк в данных\n",
    "tol = np.round(20 / (X_train.shape[0] * (4/5)), 5)\n",
    "\n",
    "# RareLabelCategoricalEncoder - для укрупнения редких категорий по порогу,\n",
    "# SimpleImputer - для обработки пропусков, выберем изначально импутацию модами,\n",
    "# обозначив 'unknown' в качестве пропущенных значений,\n",
    "# TargetEncoder - для кодирования переменных с \n",
    "# помощью среднего значения целевого признака\n",
    "\n",
    "cat_preprocessor = Pipeline([                 \n",
    "    ('rcg', RareLabelCategoricalEncoder(tol=tol,\n",
    "                                        n_categories=2,\n",
    "                                        replace_with='Rare')),\n",
    "    ('imp', PandasSimpleImputer(strategy='most_frequent',\n",
    "                                missing_values='unknown')),\n",
    "    ('enc', ce.CatBoostEncoder(cols=categorical))                          \n",
    "])\n",
    "\n",
    "\n",
    "# для числовых переменных -\n",
    "\n",
    "# MinMaxScaler - для приведения переменных к одному масштабу\n",
    "# SimpleImputer - для обработки пропусков, выберем импутацию модами\n",
    "num_preprocessor = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('imp', PandasSimpleImputer(strategy='most_frequent', \n",
    "                                fill_value=-999999999)),                       \n",
    "])\n",
    "\n",
    "\n",
    "# объединим их с помощью ColumnTransformer\n",
    "base_preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, categorical),\n",
    "    ('num', num_preprocessor, numerical)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lNwXvT9yNPjj"
   },
   "outputs": [],
   "source": [
    "# задаем список бэйзлайн-моделей\n",
    "baseline_models = [\n",
    "    BernoulliNB(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    LogisticRegression(random_state=SEED, n_jobs=-1),\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1), \n",
    "    ExtraTreesClassifier(random_state=SEED, n_jobs=-1), \n",
    "    AdaBoostClassifier(random_state=SEED),\n",
    "    XGBClassifier(random_state=SEED, tree_method='gpu_hist'),\n",
    "    LGBMClassifier(random_state=SEED),\n",
    "    CatBoostClassifier(learning_rate=0.1, n_estimators=100,\n",
    "                       random_state=SEED, task_type=\"GPU\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gjOdR7t7C2KC"
   },
   "outputs": [],
   "source": [
    "categorical_idxs = [train.columns.get_loc(c) for c in categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "executionInfo": {
     "elapsed": 327587,
     "status": "ok",
     "timestamp": 1602409895577,
     "user": {
      "displayName": "Роман Новиков",
      "photoUrl": "https://lh5.googleusercontent.com/-49FN6_YzdHQ/AAAAAAAAAAI/AAAAAAAAAC4/fOYzKlKwLu4/s64/photo.jpg",
      "userId": "04346782864121885769"
     },
     "user_tz": -180
    },
    "id": "CpAh3hC-DZEa",
    "outputId": "a10b90f8-7150-40e3-9989-43d4659cd6cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB - cv-scores: [0.638  0.6239 0.6227 0.6156 0.6204],\n",
      "              shapiro_pvalue = 0.31\n",
      "              mean score = 0.6241\n",
      "              0.95 confint: [0.6137 0.6345]\n",
      "\n",
      "GaussianNB - cv-scores: [0.6356 0.6467 0.6375 0.6356 0.639 ],\n",
      "             shapiro_pvalue = 0.07\n",
      "             mean score = 0.6389\n",
      "             0.95 confint: [0.6332 0.6446]\n",
      "\n",
      "KNeighborsClassifier - cv-scores: [0.5404 0.5555 0.5624 0.5699 0.5565],\n",
      "                       shapiro_pvalue = 0.78\n",
      "                       mean score = 0.5569\n",
      "                       0.95 confint: [0.5434 0.5705]\n",
      "\n",
      "LogisticRegression - cv-scores: [0.7147 0.6984 0.7118 0.7051 0.699 ],\n",
      "                     shapiro_pvalue = 0.38\n",
      "                     mean score = 0.7058\n",
      "                     0.95 confint: [0.6966 0.715 ]\n",
      "\n",
      "RandomForestClassifier - cv-scores: [0.6833 0.686  0.6758 0.6877 0.6578],\n",
      "                         shapiro_pvalue = 0.14\n",
      "                         mean score = 0.6781\n",
      "                         0.95 confint: [0.6629 0.6933]\n",
      "\n",
      "ExtraTreesClassifier - cv-scores: [0.6918 0.6826 0.6712 0.6769 0.6669],\n",
      "                       shapiro_pvalue = 0.90\n",
      "                       mean score = 0.6779\n",
      "                       0.95 confint: [0.6657 0.69  ]\n",
      "\n",
      "AdaBoostClassifier - cv-scores: [0.7087 0.7143 0.7107 0.7404 0.7136],\n",
      "                     shapiro_pvalue = 0.01\n",
      "                     mean score = 0.7175\n",
      "                     0.95 confint: [0.7015 0.7336]\n",
      "\n",
      "XGBClassifier - cv-scores: [0.7277 0.7305 0.7392 0.7411 0.7152],\n",
      "                shapiro_pvalue = 0.60\n",
      "                mean score = 0.7308\n",
      "                0.95 confint: [0.7179 0.7436]\n",
      "\n",
      "LGBMClassifier - cv-scores: [0.711  0.7199 0.7245 0.7324 0.7054],\n",
      "                 shapiro_pvalue = 0.93\n",
      "                 mean score = 0.7186\n",
      "                 0.95 confint: [0.7053 0.732 ]\n",
      "\n",
      "CatBoostClassifier - cv-scores: [0.7313 0.7282 0.7427 0.7459 0.718 ],\n",
      "                     shapiro_pvalue = 0.74\n",
      "                     mean score = 0.7332\n",
      "                     0.95 confint: [0.7192 0.7473]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим общий словарик для всех моделей\n",
    "models = dict()\n",
    "\n",
    "# для каждой модели\n",
    "for model_idx, model in enumerate(baseline_models):\n",
    "\n",
    "    # создаем ветку модели в общем словаре\n",
    "    model_name = model.__class__.__name__\n",
    "    models[model_name] = dict()\n",
    "    \n",
    "    # делаем точную копию пайплайна препроцессинга\n",
    "    preprocessor = deepcopy(base_preprocessor)\n",
    "    \n",
    "    # если моделью является CatBoost\n",
    "    if model_name == 'CatBoostClassifier':\n",
    "\n",
    "        # нужно отключить encoder внутри пайплайна предобработки\n",
    "        # категориальных переменных, т.к. будет использоваться\n",
    "        # встроенный в CatBoostClassifier способ кодирования переменных\n",
    "        preprocessor.set_params(**{'cat__enc': 'passthrough'})\n",
    "\n",
    "        # передаем в параметры обучения индексы категориальных переменных\n",
    "        fit_params = {'model__cat_features': categorical_idxs}\n",
    "\n",
    "    # для всех остальных моделей\n",
    "    else:\n",
    "\n",
    "        # параметры обучения оставляем пустыми\n",
    "        fit_params = None\n",
    "        \n",
    "    # создаем полный пайплайн (препроцессинг -> модель)\n",
    "    pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                      ('model', model)])\n",
    "\n",
    "    # проводим перекрестную проверку\n",
    "    scores = cross_val_score(pipe, X_train, y_train, \n",
    "                             cv=cv, scoring='roc_auc',\n",
    "                             error_score='raise', \n",
    "                             fit_params=fit_params,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "    # сохраним в ветке модели объект полного пайплайна\n",
    "    # для того, чтобы использовать его в дальнейшем\n",
    "    models[model_name]['pipe'] = pipe\n",
    "\n",
    "    # записываем cv-оценки под ключем actual\n",
    "    # для того, чтобы сравнивать любые дальнейшие \n",
    "    # изменения с оценками бэйзлайна\n",
    "    models[model_name]['actual'] = scores\n",
    "    \n",
    "    # печатаем статистики полученных оценок\n",
    "    model_message = f'{model_name} - '\n",
    "    margin = ' ' * len(model_message)\n",
    "    message = (model_message \n",
    "               + f'cv-scores: {np.round(scores, 4)},\\n' \n",
    "               + margin \n",
    "               + f'shapiro_pvalue = {ss.shapiro(scores)[1]:.2f}\\n' \n",
    "               + margin \n",
    "               + f'mean score = {scores.mean():.4f}\\n' \n",
    "               + margin \n",
    "               + f'0.95 confint: {tconfint_mean(scores)}\\n')\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fHdSI4N8qdd"
   },
   "source": [
    "По итогам проделанной проверки мною были выбраны две базовые модели для дальнейшей настройки, дающие наибольшее качество на кросс-валидации - XGBClassifier и CatBoostClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgjjRMkSuy29"
   },
   "outputs": [],
   "source": [
    "models = {model: models[model] for model in ['XGBClassifier', 'CatBoostClassifier']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Zev2e4eieMJ"
   },
   "outputs": [],
   "source": [
    "# сохраняем словарь для дальнейшей настройки параметров\n",
    "save_obj(models, '../data/models_dictionary/models_baseline.pkl')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5 ocp-baseline-selection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
